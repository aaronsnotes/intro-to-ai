Previous: [[4. Evaluation Metrics (for Classification)]]

# 1. Regression
Models the relationship between variables to predict a **numerical value**.
- **Linear regression:** fits a straight line (h<sub>w</sub>(x) = w<sub>0</sub> + w<sub>1</sub>x) to the data. The goal is to learn the coefficients (w<sub>0</sub>, w<sub>1</sub>) that minimise the L2 loss.
- **Gradient descent:** an iterative algorithm to find the minimum of a loss function. It "moves" the coefficients in small steps towards the best solution. It can get stuck in a *local minimum*.

# 2. Classification
Predicts a **finite label** (e.g., "spam" or "not-spam").
- **Logistic regression:** a classification algorithm that works by finding a **decision boundary** (a line or a curve) to separate the classes. It uses a non-linear function to output a probability (0 to 1).
- **k-Nearest Neighbours (k-NN):** a non-parametric instance-based model.
	- It doesn't "learn" a model. It stores the training data.
	- To classify a new point, it finds the **k-closest data points** (its "neighbours") in the training set.
	- The new point is assigned the class that "wins the vote" among its neighbours.

# 3. Reinforcement Learning (RL)
An agent to make decisions by interacting with an environment.
- **Policy ($pi(s)$):** the agent's strategy. It defines the probability of taking an action in a given state.
- **Utility (U<sub>pi</sub>$(s)$):** the expected future reward an agent will get from a given state, if it follows its policy.
- **Deep Reinforcement Learning (DRL):** a modern approach that uses a **Neural Network** to estimate the policy or utility function. This removes the need for handcrafted features and allows the agent to learn complex strategies directly from raw input.

Back to index: [[Intro to AI - Index]]